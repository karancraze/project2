{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Dropout\n",
    "from keras.layers import MaxPooling2D, ZeroPadding2D\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.core import Activation\n",
    "from keras import backend as K\n",
    "from keras.utils import np_utils\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data loading + reshape to 4D\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "\n",
    "X_train = X_train.reshape(-1, 28, 28)\n",
    "X_test = X_test.reshape(-1, 28, 28)\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "X_train/=255\n",
    "X_test/=255\n",
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2472608de48>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nP5AU4QeSIvxAUoQfSIrwA0kRfiCp/wNxnUFnQKXHIQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x247206eb518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(np.squeeze(X_train[65]), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, array([ 0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_of_classes = 10\n",
    "\n",
    "Y_train = np_utils.to_categorical(y_train, number_of_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, number_of_classes)\n",
    "\n",
    "y_train[0], Y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model \n",
    "model = Sequential()\n",
    "\n",
    "model.add(Convolution2D(32, (3, 3), input_shape=(28,28,1))) \n",
    "convout1 = Activation('relu')\n",
    "model.add(convout1)\n",
    "convout2 = MaxPooling2D()\n",
    "model.add(convout2)\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 26, 26, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 5408)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               692352    \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1290      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 693,962\n",
      "Trainable params: 693,962\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, batch_size=128, epochs=5, validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# choose any image to want by specifying the index\n",
    "img_to_visualize = X_train[65]\n",
    "# Keras requires the image to be in 4D\n",
    "# So we add an extra dimension to it.\n",
    "img_to_visualize = np.expand_dims(img_to_visualize, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer_to_visualize(layer):\n",
    "    inputs = [K.learning_phase()] + model.inputs\n",
    "\n",
    "    _convout1_f = K.function(inputs, [layer.output])\n",
    "    def convout1_f(X):\n",
    "        # The [0] is to disable the training phase flag\n",
    "        return _convout1_f([0] + [X])\n",
    "\n",
    "    convolutions = convout1_f(img_to_visualize)\n",
    "    convolutions = np.squeeze(convolutions)\n",
    "\n",
    "    print ('Shape of conv:', convolutions.shape)\n",
    "    \n",
    "    n = convolutions.shape[0]\n",
    "    n = int(np.ceil(np.sqrt(n)))\n",
    "    \n",
    "    # Visualization of each filter of the layer\n",
    "    fig = plt.figure(figsize=(12,8))\n",
    "    for i in range(len(convolutions)):\n",
    "        ax = fig.add_subplot(n,n,i+1)\n",
    "        ax.imshow(convolutions[i], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the layer to want to visualize\n",
    "layer_to_visualize(convout1)\n",
    "\n",
    "# As convout2 is the result of a MaxPool2D layer\n",
    "# We can see that the image has blurred since\n",
    "# the resolution has reduced \n",
    "layer_to_visualize(convout2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
